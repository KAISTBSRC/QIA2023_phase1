{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c808b4e-6c06-405f-a9ab-3176236d486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from transformers import *\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe3023f-3ac3-4a1a-b100-2151b077d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/hackathon_train.csv', encoding='cp949', index_col=0)\n",
    "\n",
    "# split train and test dataframe\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for idx in df['User_ID'].unique():\n",
    "    train_df_list.append(df[df['User_ID']==idx][0:40])\n",
    "    test_df_list.append(df[df['User_ID']==idx][40:])\n",
    "    \n",
    "train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "test_df = pd.concat(test_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18849bd-b6a3-4cf1-b60c-f4bbec19a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding\n",
    "train_result = torch.load('train_embed.pt')\n",
    "test_result = torch.load('test_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962af7ad-e05d-452c-bc04-8f293bcffbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(SEED=0):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, label_idx=0):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.label_idx = label_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], torch.tensor(self.label[idx][self.label_idx])\n",
    "    \n",
    "def convert_mbti_to_label(mbti: str):\n",
    "    \"\"\"\n",
    "    :param mbti: string. length=4\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stand = 'ISTJ'  # [0, 0, 0, 0]\n",
    "    result = []\n",
    "    for i in range(4):\n",
    "        if stand[i] == mbti[i]:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# def convert_label_to_mbti(num, label_idx):\n",
    "#     stand = 'ISTJ'\n",
    "#     mbti = stand[label_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b09c3f-a2a5-4182-87ad-168f09e92d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dl, optimizer, criterion, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.train()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "\n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def valid(model, dl, optimizer=None, criterion=None, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.eval()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    output_list = []\n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "        output_list.append(output.argmax(dim=1).cpu())\n",
    "        \n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "    \n",
    "    \n",
    "#     # userid accuracy\n",
    "#     result = 0\n",
    "#     a = torch.cat(output_list)\n",
    "#     for uid in test_df['User_ID'].unique():\n",
    "#         idx = test_df[test_df['User_ID']==uid].index\n",
    "#         if a[idx].count_nonzero().item() > len(a[idx])//2:\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             label = 0\n",
    "            \n",
    "#         result += convert_mbti_to_label(test_df[test_df['User_ID']==uid]['MBTI'].unique()[0])[label_idx] == label\n",
    "        \n",
    "    \n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c897543d-975f-4271-8efc-2f43cfe77bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, dl, device=0):\n",
    "    pooled = []\n",
    "    hidden = []\n",
    "    model.cuda(device)\n",
    "    model.eval()\n",
    "    for data in dl:\n",
    "        data = {k:v.cuda(device) for k,v in data.items()}\n",
    "        with torch.no_grad():\n",
    "            output = model(**data, output_hidden_states=True)\n",
    "        p, h = output.pooler_output, output.hidden_states\n",
    "        pooled.append(p) # pooler output\n",
    "        hidden.append(h[-1][:,0,:]) # only [CLS] token embedding \n",
    "    return torch.cat(pooled), torch.cat(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b9771c-e8bc-4e10-8b11-5ee146b2b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(label_idx=0, device=1, name='test'):\n",
    "    \n",
    "    model = nn.Sequential(nn.Linear(768, 50),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(50, 2))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    \n",
    "    \n",
    "    # dataset / dataloader\n",
    "    train_data = train_result[0] # pooler output\n",
    "    train_label = train_df['MBTI'].map(convert_mbti_to_label)\n",
    "    \n",
    "    test_data = test_result[0]\n",
    "    test_label = test_df['MBTI'].map(convert_mbti_to_label)\n",
    "    \n",
    "    train_ds = MyDataset(train_data, train_label, label_idx)\n",
    "    test_ds = MyDataset(test_data, test_label, label_idx)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # train\n",
    "    train_final = []\n",
    "    val_final = []\n",
    "    \n",
    "    save_dir = f'./ckpt/{name}'\n",
    "    for epoch in range(500):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device=device)\n",
    "        # validation\n",
    "        val_loss, val_acc = valid(model, test_dl, criterion=criterion, device=device)\n",
    "\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Acc/Train', train_acc, epoch)\n",
    "#         wandb.log({'train_loss': train_loss, 'train_acc': train_acc, 'epoch': epoch})\n",
    "        writer.add_scalar('Loss/Test', val_loss, epoch)\n",
    "        writer.add_scalar('Acc/Test', val_acc, epoch)\n",
    "#         writer.add_scalar('Acc/userid', acc, epoch)\n",
    "#         wandb.log({'val_loss': val_loss, 'val_acc': val_acc, 'epoch': epoch})\n",
    "\n",
    "        train_final.append([train_loss, train_acc])\n",
    "        val_final.append([val_loss, val_acc])\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save(model, f\"{save_dir}/epoch_{epoch}.pt\")\n",
    "\n",
    "    return train_final, val_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5198f7f7-89b5-43a1-8184-4eb34919cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all\n",
    "MBTI = ['IE', 'SN', 'TF', 'JP']\n",
    "set_random(422)\n",
    "for i in range(4):\n",
    "    writer = SummaryWriter(f'./tensorboard/test1/{MBTI[i]}/')\n",
    "    result = main(i, 7, MBTI[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
